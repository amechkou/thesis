\chapter{Related Work}
\label{chap:1}

\section{LLM Enhancement Techniques}
\label{sec:1}

LLMs have demonstrated remarkable capabilities across various natural language processing tasks, yet they face significant limitations that hinder their deployment in critical domains such as mental healthcare. This section examines three primary enhancement techniques that address these limitations: prompt engineering, retrieval-augmented generation, and fine-tuning. 

\begin{figure}[htbp]
\centering
\includegraphics[width=0.7\textwidth]{images/rag_vs_finetuning_comparison.png}
\caption{Comparison of three LLM enhancement approaches based on external knowledge and model adaptation requirements. Source: Gao et al. \cite{gao2024retrieval}}
\label{fig:llm-enhancement-comparison}
\end{figure}
\subsection{Prompt Engineering}
\label{subsec:prompt-engineering}

Prompt engineering represents the systematic practice of designing and refining input prompts to optimize LLM outputs \cite{schulhoff2024prompt, chen2024unleashing}. As the primary interface through which users interact with LLMs, carefully crafted prompts can significantly enhance model performance on complex tasks without requiring model retraining or fine-tuning \cite{schulhoff2024prompt}. This capability is particularly valuable in sensitive domains such as mental healthcare, where prompt engineering enables practitioners to adapt general-purpose models to specific use cases while maintaining safety and accuracy standards.

The foundation of prompt engineering comprises two fundamental approaches: zero-shot and few-shot prompting \cite{schulhoff2024prompt}. Zero-shot prompting provides the model with task instructions without examples, relying entirely on the model's pre-trained knowledge to generalize to new tasks. Few-shot prompting enhances this by including a small number of input-output examples within the prompt, demonstrating the desired behavior and significantly improving the model's ability to understand task-specific patterns \cite{chen2024unleashing}. Research demonstrates that few-shot prompting substantially outperforms zero-shot approaches in knowledge-intensive tasks, though the effectiveness depends critically on example selection and ordering \cite{schulhoff2024prompt}.

Chain-of-Thought prompting represents a significant advancement in eliciting reasoning capabilities from LLMs \cite{chen2024unleashing, schulhoff2024prompt}. This technique prompts the model to articulate intermediate reasoning steps before producing a final answer, either through explicit demonstrations in few-shot examples or through simple zero-shot instructions such as "Let's think step by step" \cite{chen2024unleashing}. Studies show that Chain-of-Thought prompting significantly improves accuracy on tasks requiring multi-step reasoning, particularly in domains such as mathematical problem-solving and logical inference \cite{schulhoff2024prompt}. The technique's effectiveness stems from its ability to break down complex problems into manageable sub-components, paralleling human problem-solving strategies.

Building upon Chain-of-Thought, decomposition techniques further enhance reasoning by explicitly structuring problem breakdown \cite{schulhoff2024prompt}. Least-to-most prompting decomposes complex problems into simpler sub-problems that are solved sequentially, with each solution informing the next step \cite{chen2024unleashing}. This approach has demonstrated substantial improvements in tasks involving compositional generalization and symbolic manipulation \cite{schulhoff2024prompt}. Such decomposition strategies prove particularly relevant for mental healthcare applications, where complex user situations often require systematic analysis across multiple dimensions.

For chatbot applications in sensitive domains, prompt engineering techniques offer mechanisms to control output style, tone, and safety characteristics \cite{schulhoff2024prompt}. Role prompting assigns specific personas to the model, such as "supportive counselor" or "information provider," enabling more contextually appropriate responses \cite{chen2024unleashing}. Self-consistency methods generate multiple reasoning paths and aggregate responses to improve reliability, reducing the risk of generating misleading or harmful content \cite{chen2024unleashing}. These techniques address critical concerns in mental healthcare settings, where response quality and consistency directly impact user wellbeing.

\subsection{Retrieval-Augmented Generation}
\label{subsec:rag}

LLMs demonstrate impressive language understanding and generation capabilities, yet they face three critical challenges that limit their effectiveness in knowledge-intensive domains. First, they suffer from hallucination problems, producing responses that are fluent and coherent but factually incorrect \cite{gao2024retrieval, wu2024retrieval}. Second, the knowledge stored in LLM parameters becomes outdated over time, and updating this knowledge requires costly retraining or fine-tuning processes \cite{wu2024retrieval}. Third, general-purpose LLMs lack domain-specific expertise, and developing specialized models demands substantial resources for data collection and training \cite{gao2024retrieval}.

Retrieval-Augmented Generation addresses these limitations by integrating external knowledge databases with LLMs. Rather than relying solely on parametric knowledge encoded during pre-training, RAG systems retrieve relevant information from external sources and provide this context to the LLM during inference \cite{gao2024retrieval}. This approach effectively reduces hallucinations by grounding responses in verifiable external information, enables continuous knowledge updates through database maintenance rather than model retraining, and facilitates domain specialization through the construction of targeted knowledge bases \cite{wu2024retrieval}.

The fundamental architecture of RAG consists of three core components. The retrieval module encodes both the user query and documents from the knowledge base into dense vector representations, then computes semantic similarity to identify the most relevant documents \cite{gao2024retrieval}. The generation module, typically a pre-trained LLM such as GPT or LLaMA, processes both the original query and the retrieved context to produce informed responses \cite{wu2024retrieval}. The augmentation component integrates these elements, determining how retrieved information is presented to the generator and how the final output is constructed \cite{gao2024retrieval}.

The evolution of RAG can be categorized into three developmental paradigms, each representing progressive enhancements over its predecessors \cite{gao2024retrieval}. Naive RAG follows a straightforward pipeline of indexing, retrieval, and generation, where documents are chunked and embedded, relevant chunks are retrieved based on query similarity, and the LLM generates responses using the retrieved context. 
\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{images/rag_three_paradigms.png}
\caption{Evolution of RAG paradigms: Naive, Advanced, and Modular RAG. Source: Gao et al. \cite{gao2024retrieval}}
\label{fig:rag-paradigms}
\end{figure}
While simple to implement, this approach suffers from potential retrieval of irrelevant or redundant information and lacks mechanisms to handle complex queries that require multi-step reasoning.

Advanced RAG addresses these limitations through pre-retrieval and post-retrieval optimizations \cite{gao2024retrieval}. Pre-retrieval techniques improve query quality through expansion methods that enrich sparse queries with additional context, or through decomposition strategies that break complex queries into manageable sub-queries. Post-retrieval enhancements include reranking retrieved documents to prioritize the most relevant information, and context compression techniques that reduce noise while preserving essential content \cite{wu2024retrieval}.

Modular RAG represents the current state of the art, offering flexible architectures that adapt to specific application requirements \cite{gao2024retrieval}. These systems can incorporate iterative retrieval for multi-hop reasoning tasks, integrate with fine-tuning strategies to align retriever and generator preferences, and employ adaptive mechanisms that determine when retrieval is necessary based on query characteristics.

For mental healthcare applications, RAG offers particular advantages. The technology enables chatbots to access continuously updated medical guidelines and treatment protocols without requiring model retraining. It facilitates grounding responses in evidence-based resources, thereby increasing trustworthiness and reducing the risk of harmful advice. Furthermore, RAG systems can maintain transparency by citing retrieved sources, allowing operators to verify the information basis of AI-generated suggestions \cite{wu2024retrieval}. These capabilities position RAG as a critical enabler for responsible AI deployment in sensitive domains where accuracy, recency, and verifiability of information are paramount.

\subsection{Fine-tuning}
\label{subsec:finetuning}

While prompt engineering and RAG enhance LLM capabilities without modifying model parameters, fine-tuning adapts pre-trained models to specific domains or tasks through additional training on specialized datasets \cite{kermani2025systematic}. This approach proves particularly effective for mental health applications, where domain-specific language patterns, clinical terminology, and appropriate response styles differ substantially from general conversational contexts.

% INSERT FIGURE 2 FROM KERMANI ET AL. HERE - Fine-tuning architecture with LoRA
% \begin{figure}[h]
% \centering
% \includegraphics[width=0.7\textwidth]{figures/finetuning_architecture.png}
% \caption{Architecture of fine-tuning implementation showing LoRA adapter integration. The pre-trained LLaMA 3 parameters remain frozen while small adaptation matrices are trained for parameter-efficient fine-tuning. Source: Kermani et al. \cite{kermani2025systematic}}
% \label{fig:finetuning-architecture}
% \end{figure}

The computational demands of traditional fine-tuning present significant challenges, requiring substantial GPU resources and training time. Parameter-efficient fine-tuning methods address these limitations by updating only a small subset of model parameters. Low-Rank Adaptation (LoRA) exemplifies this approach, introducing trainable low-rank matrices into the model architecture while keeping the original parameters frozen \cite{kermani2025systematic}. This technique dramatically reduces the number of trainable parameters and memory requirements while maintaining performance comparable to full fine-tuning.

In mental health applications, fine-tuning has achieved state-of-the-art results. Evaluation on emotion classification and mental health condition detection tasks demonstrates that fine-tuned models reach accuracy rates of 91\% and 80\% respectively, substantially outperforming both prompt engineering and RAG approaches \cite{kermani2025systematic}. These performance gains prove particularly valuable for basic emotion recognition tasks such as joy and sadness detection, where fine-tuned models achieve F1-scores exceeding 0.94. However, the approach requires substantial training data and computational resources, creating barriers for organizations with limited infrastructure.

The selection between fine-tuning, prompt engineering, and RAG depends on specific application requirements and available resources \cite{kermani2025systematic}. Fine-tuning delivers superior accuracy but demands extensive training data, computational capacity, and ongoing maintenance for model updates. RAG offers continuous knowledge updates through database modifications without requiring model retraining, making it suitable for scenarios where information changes frequently. Prompt engineering provides the most flexible deployment option, enabling rapid adaptation without computational overhead, though with moderate performance trade-offs. For mental health chatline support applications, a hybrid approach may prove optimal, combining fine-tuning for core capabilities with RAG for accessing current protocols and prompt engineering for flexible response generation.

% REVISED SECTION 2.2 - LLMs in Mental Health Care
% This section integrates the three papers on empathetic dialogue generation
% Replace your current "Part B" with this content

\section{LLMs in Mental Health Care}
\label{sec:llm-mental-health}

Deploying LLMs in mental healthcare requires both theoretical grounding and practical technical approaches. This section examines conceptual frameworks for therapeutic chatbots and surveys technical methods for enhancing empathy, reasoning, and dialogue control.

\subsection{Theoretical Foundations and Empathy Generation}
\label{subsec:empathy-foundations}

Grodniewicz and Hohol propose conceptualizing therapeutic chatbots as cognitive-affective artifacts rather than autonomous agents \cite{grodniewicz2024therapeutic}. This framework positions chatbots as tools supporting cognitive tasks like mood tracking while functioning as affective artifacts through emotion regulation techniques. For AI-CARES, this clarifies how LLMs augment operator capabilities through information retrieval and empathetic phrasing suggestions while maintaining human oversight.

Standard dialogue models struggle with empathy because human empathetic responses rely on external knowledge rather than surface patterns. Li et al. demonstrate that less than one percent of empathetic dialogue samples show direct word overlap between speaker and listener utterances \cite{li2022knowledge}. Their KEMP architecture addresses this through knowledge bridging, constructing emotional context graphs integrating dialogue history with ConceptNet for commonsense relations and NRC VAD for emotional lexicons. This enables retrieval of emotion-related concepts and computation of emotion intensity values informing response generation. For operator support systems, this suggests incorporating domain-specific guidelines for cognitive support and emotional lexicons for affective understanding.

Mental health systems must also align empathy intensity to situational requirements. Ma et al. propose EmpRL, using reinforcement learning to optimize empathy level alignment according to emotional reaction, interpretation, and exploration components \cite{ma2024empathy}. Each component can be expressed at no, weak, or strong levels. The system trains empathy identifiers to recognize these levels, then uses Proximal Policy Optimization to generate responses matching human reference empathy levels. This three-component model provides a concrete framework for AI-CARES benchmarking tasks, offering a principled rubric for evaluating chatbot responses and enabling operator feedback to refine model behavior through human-in-the-loop training.

\subsection{Technical Enhancement Approaches}
\label{subsec:technical-approaches}

Beyond empathy generation, mental health chatbots require robust reasoning capabilities and strategic dialogue control. CoT-RAG addresses LLM reasoning limitations by integrating Chain-of-Thought prompting with Retrieval-Augmented Generation \cite{li2025cotrag}. The framework employs knowledge graphs to modulate reasoning chain generation, enhancing credibility through three key mechanisms: knowledge graph-driven CoT generation for structured reasoning, learnable knowledge case-aware RAG that retrieves relevant sub-cases to mitigate logical errors, and pseudo-program prompting execution that guides LLMs to execute reasoning tasks programmatically rather than through natural language alone. For mental health applications, this approach offers particular value when operators need AI assistance with complex case reasoning where factual accuracy and logical consistency are critical.

Complementing reasoning enhancement, SAGE introduces State-Action Chain augmentation for strategic dialogue control \cite{zhang2025sage}. Unlike traditional next-token prediction, SAGE augments training data with explicit state tracking and policy learning tokens, enabling models to estimate dialogue state, predict actions based on current state, and generate utterances executing predicted actions. The framework employs future-aware annotation, examining complete dialogue trajectories to disambiguate speaker intent and understand conversational move consequences. This enables coarse-grained control over dialogue progression, allowing reinforcement learning to adjust action tokens rather than entire model outputs. For AI-CARES, this suggests that operator support tools could benefit from explicit dialogue state representations, enabling systems to suggest strategic conversational moves while maintaining operator control over final decisions.

SouLLMate demonstrates comprehensive integration of these technical approaches in a practical mental health support system \cite{guo2024soullmate}. The system combines LLMs, LangChain, RAG, and prompt engineering to provide functionalities including preliminary mental health assessment, suicide risk detection, and proactive guidance dialogue. SouLLMate employs RAG for personalized profile uploads and conversational information extraction, collecting key linguistic indicators to enhance various support functions. The system introduces Key Indicator Summarization for context-sensitive response adjustment and Proactive Questioning Strategy for semantic coherence evaluation. This integrated approach illustrates how multiple technical components can be orchestrated to create functional mental health support tools, providing a reference architecture for AI-CARES operator assistance systems that balance automation with human oversight.
es in role-playing scenarios and enabling operator feedback to refine model behavior through human-in-the-loop training.
